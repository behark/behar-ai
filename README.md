# Behar AI - Production Open WebUI Platform

A complete production-ready AI platform with Open WebUI, PostgreSQL, Redis, monitoring, and 7 LLM models.

## ğŸŒŸ Features

- ğŸ¤– **Open WebUI** - Modern chat interface
- ï¿½ï¸ **PostgreSQL** - Production database
- âš¡ **Redis** - High-performance caching
- ğŸ‹ **Docker** - Containerized deployment
- ğŸ“Š **Monitoring** - Prometheus + Grafana
- ğŸ”’ **Security** - User management & API keys
- ğŸ“ˆ **Analytics** - Usage tracking
- ğŸ”„ **Backup** - Automated backups

## ğŸš€ Quick Deploy

### Production Setup (Recommended)
```bash
# Clone repository
git clone https://github.com/behark/behar-ai.git
cd behar-ai

# Copy and customize environment
cp .env.production .env
nano .env  # Edit with your secure passwords

# Deploy full stack
./deploy-production.sh
```

**Services will be available at:**
- ğŸŒ **Open WebUI**: http://localhost:8080
- âš¡ **API**: http://localhost:8000
- ğŸ¤– **Ollama**: http://localhost:11434
- ğŸ“ˆ **Prometheus**: http://localhost:9090
- ğŸ“Š **Grafana**: http://localhost:3001 (admin/admin)

### Railway (Simple Deploy)
[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template)

```bash
# For simple Railway deployment
git clone https://github.com/behark/behar-ai.git
cd behar-ai
railway login
railway init
railway up
```

### Docker (Minimal)
```bash
# Quick Docker setup
git clone https://github.com/behark/behar-ai.git
cd behar-ai
docker build -t behar-ai .
docker run -p 8080:8080 behar-ai
```

## ğŸ› ï¸ Configuration

1. **Copy environment template:**
   ```bash
   cp .env.deploy .env
   ```

2. **Edit configuration:**
   - Set `WEBUI_SECRET_KEY` to a secure random string
   - Configure `OLLAMA_BASE_URL` if using external Ollama
   - Set `CORS_ALLOW_ORIGIN` to your domain

3. **Deploy and access:**
   - Railway: Automatic HTTPS URL provided
   - VPS: Configure nginx + SSL
   - Local: http://localhost:8080

## ğŸ”’ Security

- No personal data in repository
- Environment variables for secrets
- CORS protection
- Rate limiting enabled
- Authentication required

## ğŸ“Š Features

- Multiple LLM support via Ollama
- Clean, responsive web interface
- API access for integrations
- Real-time chat streaming
- Model switching
- Chat history

## ğŸ†˜ Support

For issues or questions, please open an issue in this repository.
